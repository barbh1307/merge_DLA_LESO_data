{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check LESO Shipments/Cancellations File (DISP_Shipments_Cancellations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook checks that the file containing shipment/cancellation data matches the structure of previous versions of the file. The following data files are used in this notebook:   \n",
    " - A CSV file containing state/territory names followed by their postal abbreviations. Both U.S. states and territories are required. \n",
    "   - This file can be populated with data from [US Postal Service Publication 28](https://pe.usps.com/text/pub28/28apb.htm).\n",
    "   - The postal_file variable in this notebook should be set to the name of this file.\n",
    " - An Excel file containing shipments/cancellations data for a quarter specified in the file name (for example: DISP_Shipments_Cancellations_01012020_to_03312020.xlsx).   \n",
    "   - To download the file expected by this notebook, click on 'SHIPMENTS(TRANSFERS)-CANCELLATIONS' from the *LESO Information for Shipments (Tranfers) and Cancellations of Property* section of the [DLA LESO Public Information](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/) website.   \n",
    "   - The LESO_file variable in this notebook should be set to the name of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook expects the Excel file to have two sheets. One sheet, labelled 'SHIPMENTS,' has requests by agencies made in the previous quarter. The other sheet, labelled 'CANCELLATIONS, has information about requests that have been cancelled.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'SHIPMENTS' sheet has the following fields:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory| 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| Requisition ID | string | apparently unique identifier; needs further research | 14 | [A-z0-9]{14} | no |   \n",
    "| FSC | string | [Federal Supply Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#Federal_Supply_Classification_Group_(FSCG)) consisting of the Federal Supply Group and Federal Supply Classification | 4 | \\[0-9\\]{4} | no |   \n",
    "| NIIN | string | [National Item Identification Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#National_Item_Identification_Number_(NIIN)) a Country Code followed by a 7-digit item identifier string | 9 | \\[0-9\\]{9} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| Date Shipped | datetime64 | date requested; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Justification | string | descriptive text justifying request; needs further research | varies | varies | yes |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'CANCELLATIONS' sheet has the following fields:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| Cancelled By | string | apparently agency that cancelled request; needs further research | varies | varies | yes | \n",
    "| RTD Ref | string | apparently unique identifier; needs further research | 6 or 7 | [0-9]{7} | no |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory| 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| FSC | string | [Federal Supply Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#Federal_Supply_Classification_Group_(FSCG)) consisting of the Federal Supply Group and Federal Supply Classification | 4 | \\[0-9\\]{4} | no |   \n",
    "| NIIN | string | [National Item Identification Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#National_Item_Identification_Number_(NIIN)) a Country Code followed by a 7-digit item identifier string | 9 | \\[0-9\\]{9} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| Date Requested | datetime64 | date request made; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Justification | string | descriptive text justifying request; needs further research | varies | varies | yes |   \n",
    "| Reason Cancelled | string | capitalized code followed by description of why request is cancelled; needs further research | varies | varies | yes |   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Libraries used by this notebook.\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#!python --version  #Python 3.8.5\n",
    "# sys is a standard library\n",
    "#pd.__version__      #1.1.2 \n",
    "#re.__version__     #2.2.1\n",
    "\n",
    "sys.path.insert(0, \"..\\\\..\\\\scripts\\\\\")\n",
    "from checksumfunctions import get_file_info\n",
    "from checksumfunctions import get_file_hash\n",
    "from notebookfunctions import get_unexpected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    VARIABLES THAT CAN BE CUSTOMIZED\n",
    "\n",
    "#    Enter the path to the folder containing all the data files.\n",
    "path_datafiles = \"../../data/\"\n",
    "\n",
    "#    This notebook expects a comma-separated file consisting of:\n",
    "#        full name,postal abbreviation\n",
    "#    The values can be downloaded from U.S. Postal Service Publication 28:\n",
    "#        https://pe.usps.com/text/pub28/28apb.htm\n",
    "#    \n",
    "#    Enter the name of the file containing postal codes.\n",
    "postal_file = 'USPS_StateAbbreviations.csv'\n",
    "\n",
    "#    Get the 'LESO Information for Shipments (Tranfers) and Cancellations of Property' file from \n",
    "#        Defense Logicstics Agency Law Enforcement Support Office Public Information\n",
    "#    The original name of the data file should be in the form:\n",
    "#        DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx\n",
    "#    \n",
    "#    Enter the name of the LESO file to be checked.\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_01012020_03312020.xlsx\"\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_04012020_06302020.xlsx\"\n",
    "LESO_file = \"DISP_Shipments_Cancellations_07012020_09302020.xlsx\"\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_10012020_12312020.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    VARIABLES THAT SHOULD NOT BE CHANGED\n",
    "\n",
    "#    Assume the file is good to merge.\n",
    "flag_file_good_to_merge = True\n",
    "\n",
    "#    Expected sheets based on sheets from previous files.\n",
    "expected_sheets = ['SHIPMENTS', 'CANCELLATIONS']\n",
    "\n",
    "#    Expected columns based on columns from previous files.\n",
    "expected_columns = {'SHIPMENTS': ['State', 'Station Name (LEA)', 'Requisition ID',\n",
    "                                  'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity',\n",
    "                                  'Acquisition Value', 'Date Shipped', 'Justification'],\n",
    "                    'CANCELLATIONS': ['Cancelled By', 'RTD Ref', 'State', 'Station Name (LEA)',\n",
    "                                      'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity',\n",
    "                                      'Acquisition Value', 'Date Requested', 'Justification',\n",
    "                                      'Reason Cancelled']}\n",
    "\n",
    "#    Build a dictionary of expected postal abbreviations based on the file\n",
    "#    named by the 'postal_file' variable.\n",
    "#        key: state abbreviation\n",
    "#        value: state name\n",
    "expected_postal_abbreviations = pd.read_csv(path_datafiles + postal_file, header=None,\n",
    "                                            quotechar = \"'\").set_index([1])[0].to_dict() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Read the data from the XLSX file.\n",
    "ship_canc_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_file, sheet_name=None)\n",
    "#    ship_canc_dict is a dictionary of all sheets in the LESO_file\n",
    "#        keys are 'SHIPMENTS', 'CANCELLATIONS'\n",
    "#        values are a single dataframe, columns vary in each dataframe\n",
    "#    The records are not cumulative from quarter to quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This notebook is checking: ')\n",
    "print('%s\\t%s\\t%s' % get_file_info(path_datafiles + LESO_file))\n",
    "print('MD5\\t %s' % get_file_hash(path_datafiles + LESO_file, 'md5'))\n",
    "print('SHA256\\t %s' % get_file_hash(path_datafiles + LESO_file, 'sha256'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THESE QUESTIONS DECIDE IF THIS FILE CAN BE MERGED WITH FILES FROM PREVIOUS QUARTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION A: Does the file have the expected sheets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sheets, missing_sheets, unexpected_sheets = '', '', ''\n",
    "found_sheets = list(ship_canc_dict.keys())\n",
    "if (found_sheets == expected_sheets):\n",
    "    print('Only the expected sheets were found.')\n",
    "    good_sheets = found_sheets\n",
    "else:\n",
    "    missing_sheets = get_unexpected_values(set(expected_sheets), set(found_sheets))\n",
    "    unexpected_sheets = get_unexpected_values(set(found_sheets), set(expected_sheets))\n",
    "    if (len(missing_sheets) > 0):\n",
    "        print('Shipments_Cancellations file has the following missing sheets:\\n', missing_sheets)\n",
    "    if (len(unexpected_sheets) > 0):\n",
    "        print('Shipments_Cancellations file has the following unexpected sheets:\\n', unexpected_sheets)\n",
    "    good_sheets = set(found_sheets).difference(set(unexpected_sheets))\n",
    "    flag_file_good_to_merge = False\n",
    "sheet_discrepancy = [missing_sheets, unexpected_sheets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION B: Are the values of 'State' valid U.S. postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_state_abbreviations = []\n",
    "for sheet_name in good_sheets:\n",
    "    unexpected_state_abbreviations_by_sheet = ([state_abbr for state_abbr in ship_canc_dict[sheet_name]['State']\n",
    "                                                if state_abbr not in expected_postal_abbreviations])\n",
    "    if (len(unexpected_state_abbreviations_by_sheet) == 0):\n",
    "        print('Only valid state and territory abbreviations found in the', sheet_name, 'sheet.')\n",
    "    else:\n",
    "        print('These state or territory abbreviations are not valid in the', sheet_name, 'sheet:\\n',\n",
    "          [unexpected_abbreviation for unexpected_abbreviation in unexpected_state_abbreviations_by_sheet])\n",
    "        unexpected_postal_abbreviations = [*unexpected_state_abbreviations, \n",
    "                                          *unexpected_state_abbreviations_by_sheet]\n",
    "        flag_file_good_to_merge = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION C: Do all sheets have the expected columns? (Each sheet should have a different set of columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = []\n",
    "unexpected_columns = []\n",
    "for sheet_name in good_sheets:\n",
    "    missing_columns_by_sheet = get_unexpected_values(set(ship_canc_dict[sheet_name].columns),\n",
    "                                            set(expected_columns[sheet_name]))\n",
    "    unexpected_columns_by_sheet = get_unexpected_values(set(expected_columns[sheet_name]),\n",
    "                                               set(ship_canc_dict[sheet_name].columns))    \n",
    "    if (len(missing_columns_by_sheet) == 0) & (len(unexpected_columns_by_sheet) == 0):\n",
    "        print('Only expected columns were found in the', sheet_name, 'sheet.')\n",
    "    else:\n",
    "        if (len(missing_columns_by_sheet) > 0):\n",
    "            print('These columns are missing from the', sheet_name, 'sheet:\\n',missing_columns_by_sheet)\n",
    "            missing_columns = [*missing_columns, *missing_columns_by_sheet]\n",
    "        if (len(unexpected_columns_by_sheet) > 0):\n",
    "            print('These unexpected columns were found in the', sheet_name, 'sheet:\\n',\n",
    "                  unexpected_columns_by_sheet)\n",
    "            unexpected_columns = [*unexpected_columns, *unexpected_columns_by_sheet]\n",
    "        flag_file_good_to_merge = False\n",
    "column_discrepancy = [missing_columns, unexpected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION D: Can this file be merged with DLA LESO Public Data files from previous quarters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_file_good_to_merge:\n",
    "    print('Yes, this file can be merged with DLA LESO Public Data files from previous quarters.')\n",
    "else:\n",
    "    print('No, this file cannot be merged for the following reasons:')\n",
    "    if (len(sheet_discrepancy[0]) + len(sheet_discrepancy[1]) > 0):\n",
    "        print('See Question A')\n",
    "    if len(inconsistant_state_abbreviations) > 0:\n",
    "        print('See Question B')\n",
    "    if (len(column_discrepancy[0]) + len(column_discrepancy[1]) > 0):\n",
    "        print('See Question C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDITIONAL INFORMATION ABOUT THE ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 1: What is the basic shape of the data in each sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name in good_sheets:\n",
    "    print('The', sheet_name, 'sheet has shape:', ship_canc_dict[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 2: What fields have null values in the original file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = []\n",
    "for sheet_name in good_sheets:\n",
    "    a_list = [(k,v) for k,v in ship_canc_dict[sheet_name].isna().sum().iteritems()\n",
    "              if v > 0]\n",
    "    null_counts.append({sheet_name: a_list})\n",
    "for a_dict in null_counts:\n",
    "    for key in a_dict:\n",
    "        if not a_dict[key]:\n",
    "            print('The', key, 'sheet has no null values.')\n",
    "        else:\n",
    "            print('The', key, 'sheet has null values in the following columns:')\n",
    "            for a_tuple in a_dict[key]:\n",
    "                print('\\t', a_tuple[0], ' (' + str(a_tuple[1]) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 3: How many unique values are in each column of the 'SHIPMENTS' sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SHIPMENTS' not in good_sheets:\n",
    "    print('Cannot count the unique values in the SHIPMENTS sheet because the sheet is missing from the file.')\n",
    "else:\n",
    "    unique_counts = ship_canc_dict['SHIPMENTS'].groupby('State', as_index=False).nunique()\n",
    "    unique_counts['State Name'] = [expected_postal_abbreviations[i] for i in unique_counts['State']]\n",
    "    display(pd.concat([pd.DataFrame([ship_canc_dict['SHIPMENTS'].nunique()], index=['Total']),\n",
    "               unique_counts.set_index('State Name')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 4: How many unique values are in each column of the 'CANCELLATIONS' sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CANCELLATIONS' not in good_sheets:\n",
    "    print('Cannot count the unique values in the CANCELLATIONS sheet because the sheet is missing from the file.')\n",
    "else:\n",
    "    unique_counts = ship_canc_dict['CANCELLATIONS'].groupby('State', as_index=False).nunique()\n",
    "    unique_counts['State Name'] = [expected_postal_abbreviations[i] for i in unique_counts['State']]\n",
    "    display(pd.concat([pd.DataFrame([ship_canc_dict['CANCELLATIONS'].nunique()], index=['Total']),\n",
    "               unique_counts.set_index('State Name')]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
