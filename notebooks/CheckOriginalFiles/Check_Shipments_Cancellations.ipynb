{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check LESO Shipments/Cancellations File (DISP_Shipments_Cancellations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook checks that the specified quarterly *LESO Information for Shipments (Tranfers) and Cancellations of Property* file, named DISP_Shipments_Cancellations_mmddyyyy_to_mmddyyyy.xlsx, matches the structure of previous versions of the file. The following data files are used in this notebook:   \n",
    " - A CSV file containing state/territory names followed by their postal abbreviations. Both U.S. states and territories are required. This file can be populated with data from [US Postal Service Publication 28](https://pe.usps.com/text/pub28/28apb.htm).   \n",
    " - [LESO Information for Shipments (Tranfers) and Cancellations of Property](https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/). To download the correct file for this notebook, click on 'SHIPMENTS(TRANSFERS)-CANCELLATIONS' from this section of the website:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![see https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/](../Images/DISP_Shipments_CancellationsXLSX.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XLSX *LESO Shipments/Cancellations* file has two sheets. One sheet, labelled 'SHIPMENTS,' has requests by agencies made in the previous quarter. The other sheet, labelled 'CANCELLATIONS, has information about requests that have been cancelled.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'SHIPMENTS' sheet has the following fields:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory| 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| Requisition ID | string | apparently unique identifier; needs further research | 14 | [A-z0-9]{14} | no |   \n",
    "| FSC | string | [Federal Supply Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#Federal_Supply_Classification_Group_(FSCG)) consisting of the Federal Supply Group and Federal Supply Classification | 4 | \\[0-9\\]{4} | no |   \n",
    "| NIIN | string | [National Item Identification Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#National_Item_Identification_Number_(NIIN)) a Country Code followed by a 7-digit item identifier string | 9 | \\[0-9\\]{9} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| Date Shipped | datetime64 | date requested; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Justification | string | descriptive text justifying request; needs further research | varies | varies | yes |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'CANCELLATIONS' sheet has the following fields:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| Cancelled By | string | apparently agency that cancelled request; needs further research | varies | varies | yes | \n",
    "| RTD Ref | string | apparently unique identifier; needs further research | 6 or 7 | [0-9]{7} | no |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory| 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| FSC | string | [Federal Supply Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#Federal_Supply_Classification_Group_(FSCG)) consisting of the Federal Supply Group and Federal Supply Classification | 4 | \\[0-9\\]{4} | no |   \n",
    "| NIIN | string | [National Item Identification Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#National_Item_Identification_Number_(NIIN)) a Country Code followed by a 7-digit item identifier string | 9 | \\[0-9\\]{9} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| Date Requested | datetime64 | date request made; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Justification | string | descriptive text justifying request; needs further research | varies | varies | yes |   \n",
    "| Reason Cancelled | string | capitalized code followed by description of why request is cancelled; needs further research | varies | varies | yes |   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Libraries used by this notebook.\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#!python --version  #Python 3.8.5\n",
    "# sys is a standard library\n",
    "#pd.__version__      #1.1.2 \n",
    "#re.__version__     #2.2.1\n",
    "\n",
    "sys.path.insert(0, \"..\\\\..\\\\scripts\\\\\")\n",
    "from checksumfunctions import get_file_info\n",
    "from checksumfunctions import get_file_hash\n",
    "from notebookfunctions import get_unexpected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    VARIABLES THAT CAN BE CUSTOMIZED\n",
    "\n",
    "#    Enter the path to the folder containing all the data files.\n",
    "path_datafiles = \"../../data/\"\n",
    "\n",
    "#    This notebook expects a comma-separated file consisting of:\n",
    "#        full name,postal abbreviation\n",
    "#    The values can be downloaded from U.S. Postal Service Publication 28:\n",
    "#        https://pe.usps.com/text/pub28/28apb.htm\n",
    "#    \n",
    "#    Enter the name of the file containing postal codes.\n",
    "postal_file = 'USPS_StateAbbreviations.csv'\n",
    "\n",
    "#    Get the 'LESO Information for Shipments (Tranfers) and Cancellations of Property' file from \n",
    "#        Defense Logicstics Agency Law Enforcement Support Office Public Information\n",
    "#    The original name of the data file should be in the form:\n",
    "#        DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx\n",
    "#    \n",
    "#    Enter the name of the LESO file to be checked.\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_01012020_03312020.xlsx\"\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_04012020_06302020.xlsx\"\n",
    "LESO_file = \"DISP_Shipments_Cancellations_07012020_09302020.xlsx\"\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_10012020_12312020.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    VARIABLES THAT SHOULD NOT BE CHANGED\n",
    "\n",
    "#    Assume the file is good to merge.\n",
    "flag_file_good_to_merge = True\n",
    "\n",
    "#    Expected sheets based on sheets from previous files.\n",
    "expected_sheets = ['SHIPMENTS', 'CANCELLATIONS']\n",
    "\n",
    "#    Expected columns based on columns from previous files.\n",
    "expected_columns = {'SHIPMENTS': ['State', 'Station Name (LEA)', 'Requisition ID',\n",
    "                                  'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity',\n",
    "                                  'Acquisition Value', 'Date Shipped', 'Justification'],\n",
    "                    'CANCELLATIONS': ['Cancelled By', 'RTD Ref', 'State', 'Station Name (LEA)',\n",
    "                                      'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity',\n",
    "                                      'Acquisition Value', 'Date Requested', 'Justification',\n",
    "                                      'Reason Cancelled']}\n",
    "\n",
    "#    Build a dictionary of expected postal abbreviations based on the file\n",
    "#    named by the 'postal_file' variable.\n",
    "#        key: state abbreviation\n",
    "#        value: state name\n",
    "expected_postal_abbreviations = pd.read_csv(path_datafiles + postal_file, header=None,\n",
    "                                            quotechar = \"'\").set_index([1])[0].to_dict() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Read the data from the XLSX file.\n",
    "ship_canc_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_file, sheet_name=None)\n",
    "#    ship_canc_dict is a dictionary of all sheets in the LESO_file\n",
    "#        keys are 'SHIPMENTS', 'CANCELLATIONS'\n",
    "#        values are a single dataframe, columns vary in each dataframe\n",
    "#    The records are not cumulative from quarter to quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This notebook is checking: ')\n",
    "print('%s\\t%s\\t%s' % get_file_info(path_datafiles + LESO_file))\n",
    "print('MD5\\t %s' % get_file_hash(path_datafiles + LESO_file, 'md5'))\n",
    "print('SHA256\\t %s' % get_file_hash(path_datafiles + LESO_file, 'sha256'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THESE QUESTIONS DECIDE IF THIS FILE CAN BE MERGED WITH FILES FROM PREVIOUS QUARTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION A: Does the file have the expected sheets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sheets, missing_sheets, unexpected_sheets = '', '', ''\n",
    "found_sheets = list(ship_canc_dict.keys())\n",
    "if (found_sheets == expected_sheets):\n",
    "    print('Only the expected sheets were found.')\n",
    "    good_sheets = found_sheets\n",
    "else:\n",
    "    missing_sheets = get_unexpected_values(set(expected_sheets), set(found_sheets))\n",
    "    unexpected_sheets = get_unexpected_values(set(found_sheets), set(expected_sheets))\n",
    "    if (len(missing_sheets) > 0):\n",
    "        print('Shipments_Cancellations file has the following missing sheets:\\n', missing_sheets)\n",
    "    if (len(unexpected_sheets) > 0):\n",
    "        print('Shipments_Cancellations file has the following unexpected sheets:\\n', unexpected_sheets)\n",
    "    good_sheets = set(found_sheets).difference(set(unexpected_sheets))\n",
    "    flag_file_good_to_merge = False\n",
    "sheet_discrepancy = [missing_sheets, unexpected_sheets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION B: Are the values of 'State' valid U.S. postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_state_abbreviations = []\n",
    "for sheet_name in good_sheets:\n",
    "    unexpected_state_abbreviations_by_sheet = ([state_abbr for state_abbr in ship_canc_dict[sheet_name]['State']\n",
    "                                                if state_abbr not in expected_postal_abbreviations])\n",
    "    if (len(unexpected_state_abbreviations_by_sheet) == 0):\n",
    "        print('Only valid state and territory abbreviations found in the', sheet_name, 'sheet.')\n",
    "    else:\n",
    "        print('These state or territory abbreviations are not valid in the', sheet_name, 'sheet:\\n',\n",
    "          [unexpected_abbreviation for unexpected_abbreviation in unexpected_state_abbreviations_by_sheet])\n",
    "        unexpected_postal_abbreviations = [*unexpected_state_abbreviations, \n",
    "                                          *unexpected_state_abbreviations_by_sheet]\n",
    "        flag_file_good_to_merge = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION C: Do all sheets have the expected columns? (Each sheet should have a different set of columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = []\n",
    "unexpected_columns = []\n",
    "for sheet_name in good_sheets:\n",
    "    missing_columns_by_sheet = get_unexpected_values(set(ship_canc_dict[sheet_name].columns),\n",
    "                                            set(expected_columns[sheet_name]))\n",
    "    unexpected_columns_by_sheet = get_unexpected_values(set(expected_columns[sheet_name]),\n",
    "                                               set(ship_canc_dict[sheet_name].columns))    \n",
    "    if (len(missing_columns_by_sheet) == 0) & (len(unexpected_columns_by_sheet) == 0):\n",
    "        print('Only expected columns were found in the', sheet_name, 'sheet.')\n",
    "    else:\n",
    "        if (len(missing_columns_by_sheet) > 0):\n",
    "            print('These columns are missing from the', sheet_name, 'sheet:\\n',missing_columns_by_sheet)\n",
    "            missing_columns = [*missing_columns, *missing_columns_by_sheet]\n",
    "        if (len(unexpected_columns_by_sheet) > 0):\n",
    "            print('These unexpected columns were found in the', sheet_name, 'sheet:\\n',\n",
    "                  unexpected_columns_by_sheet)\n",
    "            unexpected_columns = [*unexpected_columns, *unexpected_columns_by_sheet]\n",
    "        flag_file_good_to_merge = False\n",
    "column_discrepancy = [missing_columns, unexpected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION D: Can this file be merged with DLA LESO Public Data files from previous quarters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_file_good_to_merge:\n",
    "    print('Yes, this file can be merged with DLA LESO Public Data files from previous quarters.')\n",
    "else:\n",
    "    print('No, this file cannot be merged for the following reasons:')\n",
    "    if (len(sheet_discrepancy[0]) + len(sheet_discrepancy[1]) > 0):\n",
    "        print('See Question A')\n",
    "    if len(inconsistant_state_abbreviations) > 0:\n",
    "        print('See Question B')\n",
    "    if (len(column_discrepancy[0]) + len(column_discrepancy[1]) > 0):\n",
    "        print('See Question C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDITIONAL INFORMATION ABOUT THE ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 1: What is the basic shape of the data in each sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name in good_sheets:\n",
    "    print('The', sheet_name, 'sheet has shape:', ship_canc_dict[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 2: What fields have null values in the original file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = []\n",
    "for sheet_name in good_sheets:\n",
    "    a_list = [(k,v) for k,v in ship_canc_dict[sheet_name].isna().sum().iteritems()\n",
    "              if v > 0]\n",
    "    null_counts.append({sheet_name: a_list})\n",
    "for a_dict in null_counts:\n",
    "    for key in a_dict:\n",
    "        if not a_dict[key]:\n",
    "            print('The', key, 'sheet has no null values.')\n",
    "        else:\n",
    "            print('The', key, 'sheet has null values in the following columns:')\n",
    "            for a_tuple in a_dict[key]:\n",
    "                print('\\t', a_tuple[0], ' (' + str(a_tuple[1]) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 3: How many unique values are in each column of the 'SHIPMENTS' sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'SHIPMENTS' not in good_sheets:\n",
    "    print('Cannot count the unique values in the SHIPMENTS sheet because the sheet is missing from the file.')\n",
    "else:\n",
    "    unique_counts = ship_canc_dict['SHIPMENTS'].groupby('State', as_index=False).nunique()\n",
    "    unique_counts['State Name'] = [expected_postal_abbreviations[i] for i in unique_counts['State']]\n",
    "    display(pd.concat([pd.DataFrame([ship_canc_dict['SHIPMENTS'].nunique()], index=['Total']),\n",
    "               unique_counts.set_index('State Name')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION 4: How many unique values are in each column of the 'CANCELLATIONS' sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CANCELLATIONS' not in good_sheets:\n",
    "    print('Cannot count the unique values in the CANCELLATIONS sheet because the sheet is missing from the file.')\n",
    "else:\n",
    "    unique_counts = ship_canc_dict['CANCELLATIONS'].groupby('State', as_index=False).nunique()\n",
    "    unique_counts['State Name'] = [expected_postal_abbreviations[i] for i in unique_counts['State']]\n",
    "    display(pd.concat([pd.DataFrame([ship_canc_dict['CANCELLATIONS'].nunique()], index=['Total']),\n",
    "               unique_counts.set_index('State Name')]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
